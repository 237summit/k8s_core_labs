kubeadm을 이용해 HA control-plane cluster 구축

1. Installing runtime
yum install -y yum-utils
yum-config-manager   --add-repo    https://download.docker.com/linux/centos/docker-ce.repo
yum install docker-ce docker-ce-cli containerd.io -y
systemctl start docker && systemctl enable docker
cat << END > /etc/docker/daemon.json
{
  "insecure-registries": ["10.100.0.0/24"],
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
systemctl restart docker 
docker version

# Installing runtime
# kubernetes는 기본으로 CRI(Container Runtime Interface)를 사용하여 컨테이너 런타임과 연동된다.  
# Runtime		Path to Unix domain socket
# Docker		/var/run/docker.sock
# containerd		/run/containerd/containerd.sock
# CRI-O		/var/run/crio/crio.sock
# https://kubernetes.io/ko/docs/setup/production-environment/container-runtimes/


2. Installing kubeadm
1) 설치전 환경설정
# Full network connectivity between all machines in the cluster (public or private network is fine).
# Unique hostname, MAC address, and product_uuid for every node. See here for more details.
# master1,2,3 worker1,2 시스템의 unique hostname, unique mac address구성해서 서로가 네트워크가 되도록 연결

# Certain ports are open on your machines. See here for more details.
# 몇 개의 포트를 오픈해야 한다. 자세한 포트리스트 확인
systemctl stop firewalld && systemctl disable firewalld

# Swap disabled. You MUST disable swap in order for the kubelet to work properly.
# kubelet을 제대로 동작시키려면 스왑을 비활성화해야 한다.
swapoff -a && sed -i '/swap/s/^/#/' /etc/fstab

# br_netfilter 모듈이 로드되었는지 확인
# Linux 노드의 iptables가 브리지 된 트래픽을 올바르게 운영할 수 있도록 sysctl 구성에서 net.bridge.bridge-nf-call-iptables가 1로 설정해야 함.
cat <<EOF |  tee /etc/modules-load.d/k8s.conf
br_netfilter
EOF

cat <<EOF |  tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sudo sysctl --system


# Set SELinux in permissive mode (effectively disabling it)
setenforce 0
sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

2) kubeadm, kubectl, kubelet 설치
# Installing kubeadm, kubelet and kubectl
cat <<EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
systemctl enable --now kubelet

systemctl status kubelet


3. LB(Load Balancer)구성(10.100.0.254)
1) SSH to the loadbalancer host.
2) Create the directory /etc/nginx.
# mkdir /etc/nginx

3) Add and edit the file /etc/nginx/nginx.conf.
vim /etc/nginx/nginx.conf
events { }
stream {
    upstream stream_backend {
        least_conn;
        server 10.100.0.101:6443;
        server 10.100.0.102:6443;
        server 10.100.0.103:6443;
    }

    server {
        listen        6443;
        proxy_pass    stream_backend;
        proxy_timeout 300s;
        proxy_connect_timeout 1s;
    }
}


4) Start NGINX.
docker run --name proxy -v /etc/nginx/nginx.conf:/etc/nginx/nginx.conf:ro --restart=always -p 6443:6443 -d nginx

curl 10.100.0.254:6443


4. kubeadm을 이용한 HA 클러스터 구성

1) master1 : kubeadm init 명령으로 초기화 - LB 등록
kubeadm init --control-plane-endpoint "lb.example.com:6443" --upload-certs
---
[init] Using Kubernetes version: v1.20.2
[preflight] Running pre-flight checks
…
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

…

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join lb.example.com:6443 --token i5401d.l9tx8jwyliwag2ej \
    --discovery-token-ca-cert-hash sha256:7158a3de268e21ed251f07648d736ec936e6b14a41c7df2f9c4c429468940920 \
    --control-plane --certificate-key 970a0b34e810c6b581fbe296dd5bd32ef8c363c91f935d97a98f0dc0021906e8

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join lb.example.com:6443 --token i5401d.l9tx8jwyliwag2ej \
    --discovery-token-ca-cert-hash sha256:7158a3de268e21ed251f07648d736ec936e6b14a41c7df2f9c4c429468940920 


cat > master.token
  kubeadm …

cat > node.token
kubeadm join lb.example.com:6443 --…

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


5. master2, master3을 master1에 join
1) master2,3을 master1과 join
kubeadm join lb.example.com:6443 --token …

2) CNI(Container Network Interface) 설치 : master1
# CNI 플러그인 적용 - weave
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
kubectl get nodes


6. worker node를 LB통해 master와 join
kubeadm join lb.example.com:6443 --token ..

#설치된 시스템 확인
kubectl get nodes
